# 오프라인 우선 AI 영단어 앱 개발 계획

## 프로젝트 개요
React Native (Expo) 기반의 오프라인 우선 AI 영단어 학습 앱 개발 프로젝트

---

## 1. 데이터베이스 준비 단계

### 1.1 데이터 소스 수집 및 분석
- 1.1.1 한국 교육부 지정 초/중/고 어휘 목록 다운로드 및 분석
- 1.1.2 GitHub 오픈소스 영한사전 데이터 (stelo/kor-eng-dictionary) 수집
- 1.1.3 Tatoeba 프로젝트 예문 데이터 수집 및 필터링
- 1.1.4 각 데이터 소스의 형식 및 구조 분석

### 1.2 데이터 정제 및 통합
- 1.2.1 교육부 어휘 목록 정제 (중복 제거, 난이도 분류)
- 1.2.2 영한사전 데이터 정제 (품사, 뜻 정보 표준화)
- 1.2.3 예문 데이터 정제 (적절한 길이, 난이도별 필터링)
- 1.2.4 세 데이터 소스 간 단어 매칭 및 통합

### 1.3 SQLite 데이터베이스 스키마 설계
- 1.3.1 Words 테이블 설계 (단어, 품사, 뜻, 난이도 등)
- 1.3.2 Examples 테이블 설계 (예문 정보)
- 1.3.3 Wordbooks 테이블 설계 (사용자 단어장)
- 1.3.4 WordbookWords 테이블 설계 (단어장-단어 연결)
- 1.3.5 StudyProgress 테이블 설계 (학습 진도 추적)

### 1.4 SQLite DB 파일 생성
- 1.4.1 Python 스크립트로 데이터 삽입 로직 구현
- 1.4.2 최종 vocabulary.db 파일 생성
- 1.4.3 데이터 무결성 검증 및 테스트
- 1.4.4 DB 파일 크기 최적화

---

## 2. 프로젝트 환경 설정

### 2.1 Expo 프로젝트 초기 설정
- 2.1.1 `npx create-expo-app` 으로 프로젝트 생성
- 2.1.2 TypeScript 설정 및 구성
- 2.1.3 필수 의존성 패키지 설치 (expo-sqlite-next, react-navigation 등)
- 2.1.4 프로젝트 폴더 구조 생성 (src/screens, src/components 등)

### 2.2 개발 환경 구성
- 2.2.1 ESLint, Prettier 설정
- 2.2.2 VS Code 설정 파일 구성
- 2.2.3 Git 저장소 초기화 및 .gitignore 설정
- 2.2.4 package.json 스크립트 설정

### 2.3 카메라 및 OCR 라이브러리 설정
- 2.3.1 react-native-vision-camera 설치 및 설정
- 2.3.2 Frame Processor 설정 (온디바이스 OCR)
- 2.3.3 카메라 권한 설정 (iOS/Android)
- 2.3.4 기본 카메라 기능 테스트

### 2.4 기본 UI 라이브러리 설정
- 2.4.1 React Navigation 설정 및 기본 네비게이션 구조
- 2.4.2 스타일링 시스템 구성 (StyleSheet, 색상 팔레트)
- 2.4.3 공통 컴포넌트 기본 틀 생성
- 2.4.4 아이콘 및 폰트 설정

---

## 3. 핵심 기능 구현

### 3.1 데이터베이스 연동 시스템
- 3.1.1 `src/database/database.ts` 기본 구조 구현
- 3.1.2 앱 초기 실행 시 assets DB 파일 복사 로직
- 3.1.3 SQLite 연결 및 기본 CRUD 함수 구현
- 3.1.4 데이터베이스 마이그레이션 시스템 구축

### 3.2 TypeScript 타입 시스템
- 3.2.1 `src/types/types.ts` 핵심 타입 정의
- 3.2.2 Word, Wordbook, StudyProgress 등 주요 인터페이스
- 3.2.3 API 응답 타입 및 상태 관리 타입 정의
- 3.2.4 전역 타입 export/import 구조 설정

### 3.3 단어장 생성 기능 (OCR 스캔)
- 3.3.1 카메라 스크린 UI 구현 (`CameraScreen.tsx`)
- 3.3.2 카메라 프리뷰 및 촬영 기능 구현
- 3.3.3 OCR 텍스트 추출 로직 구현 (Frame Processor)
- 3.3.4 `src/services/ocrService.ts` 후처리 로직 구현
- 3.3.5 추출된 텍스트와 로컬 DB 단어 매칭
- 3.3.6 사용자 단어 수정/선택 UI 구현
- 3.3.7 새 단어장 생성 및 단어 추가 기능

### 3.4 단어장 관리 기능
- 3.4.1 단어장 목록 화면 (`WordbookScreen.tsx`) 구현
- 3.4.2 단어장 상세 보기 화면 구현
- 3.4.3 단어장 생성/수정/삭제 기능
- 3.4.4 단어 추가/제거 기능
- 3.4.5 단어장 검색 및 필터링 기능

### 3.5 단어 상세 정보 기능
- 3.5.1 개별 단어 상세 보기 화면 구현
- 3.5.2 로컬 DB에서 단어 정보 (뜻, 품사, 예문) 표시
- 3.5.3 네이버 사전 웹페이지 연동 (WebView/InAppBrowser)
- 3.5.4 단어 즐겨찾기 기능
- 3.5.5 학습 상태 표시 및 관리

### 3.6 학습 모드 구현
- 3.6.1 플래시카드 학습 화면 구현
- 3.6.2 단어 ↔ 뜻 양방향 학습 기능
- 3.6.3 학습 진도 추적 및 저장
- 3.6.4 반복 학습 알고리즘 구현 (간격 반복)
- 3.6.5 학습 통계 및 진도 표시

### 3.7 퀴즈/시험 모드 구현
- 3.7.1 퀴즈 문제 생성 로직 (`src/services/quizService.ts`)
- 3.7.2 객관식 문제 화면 구현
- 3.7.3 시험 모드 진행 화면 구현
- 3.7.4 모든 문제 완료 후 결과 화면 구현
- 3.7.5 틀린 문제 복습 기능
- 3.7.6 성취도 분석 및 약점 파악

---

## 4. 사용자 경험 개선

### 4.1 네비게이션 및 UI/UX 개선
- 4.1.1 직관적인 탭 네비게이션 구현
- 4.1.2 일관된 디자인 시스템 적용
- 4.1.3 로딩 상태 및 에러 처리 UI
- 4.1.4 접근성 (Accessibility) 개선

### 4.2 성능 최적화
- 4.2.1 리스트 렌더링 최적화 (FlatList 등)
- 4.2.2 이미지 및 메모리 관리 최적화
- 4.2.3 데이터베이스 쿼리 최적화
- 4.2.4 앱 시작 시간 최적화

### 4.3 오프라인 기능 강화
- 4.3.1 네트워크 상태 감지 및 처리
- 4.3.2 오프라인 상태에서의 모든 기능 동작 확인
- 4.3.3 데이터 동기화 전략 (향후 온라인 기능 확장 대비)

---

## 5. 테스트 및 검증

### 5.1 기능 테스트
- 5.1.1 각 화면별 기능 동작 테스트
- 5.1.2 OCR 정확도 및 후처리 로직 검증
- 5.1.3 데이터베이스 CRUD 동작 검증
- 5.1.4 학습/퀴즈 로직 정확성 테스트

### 5.2 사용성 테스트
- 5.2.1 실제 사용자 시나리오 테스트
- 5.2.2 다양한 이미지/텍스트 조건에서 OCR 테스트
- 5.2.3 장시간 사용 시 성능 및 메모리 테스트

### 5.3 디바이스 호환성 테스트
- 5.3.1 iOS 시뮬레이터/실기기 테스트
- 5.3.2 Android 에뮬레이터/실기기 테스트
- 5.3.3 다양한 화면 크기 대응 테스트

---

## 6. 빌드 및 배포 준비

### 6.1 프로덕션 빌드 설정
- 6.1.1 앱 아이콘 및 스플래시 스크린 설정
- 6.1.2 app.json/app.config.js 최종 설정
- 6.1.3 번들 크기 최적화
- 6.1.4 프로덕션 빌드 테스트

### 6.2 스토어 배포 준비
- 6.2.1 앱 스토어 메타데이터 준비
- 6.2.2 스크린샷 및 프로모션 이미지 제작
- 6.2.3 개인정보처리방침 및 이용약관 작성
- 6.2.4 EAS Build 설정 (선택사항)

---

## 7. 향후 확장 계획

### 7.1 추가 기능 구상
- 7.1.1 사용자 계정 및 클라우드 동기화
- 7.1.2 소셜 기능 (단어장 공유 등)
- 7.1.3 AI 기반 개인화 학습 추천
- 7.1.4 음성 발음 기능

### 7.2 기술적 개선사항
- 7.2.1 더 정확한 OCR 모델 도입
- 7.2.2 오프라인 AI 번역 기능
- 7.2.3 앱 성능 모니터링 시스템
- 7.2.4 자동 업데이트 시스템

---

## 개발 우선순위 및 예상 소요 시간

**Phase 1 (1-2주)**: 데이터베이스 준비 (1.1 ~ 1.4)
**Phase 2 (1주)**: 프로젝트 환경 설정 (2.1 ~ 2.4)  
**Phase 3 (2-3주)**: 핵심 기능 구현 (3.1 ~ 3.7)
**Phase 4 (1주)**: 사용자 경험 개선 (4.1 ~ 4.3)
**Phase 5 (1주)**: 테스트 및 검증 (5.1 ~ 5.3)
**Phase 6 (1주)**: 빌드 및 배포 준비 (6.1 ~ 6.2)

**총 예상 개발 기간: 7-9주**

---

## 주요 체크포인트

- [ ] 로컬 DB 파일 완성 및 검증
- [ ] OCR 기본 기능 동작 확인  
- [ ] 단어장 생성 플로우 완성
- [ ] 학습 모드 기본 기능 완성
- [ ] 퀴즈 모드 완성
- [ ] 전체 앱 플로우 테스트 완료
- [ ] 프로덕션 빌드 성공

이 계획을 통해 체계적이고 단계적으로 오프라인 우선 AI 영단어 앱을 완성할 수 있습니다.